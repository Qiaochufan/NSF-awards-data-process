{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd407036-a5c7-4d13-a640-b400be552e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "def search_crossref(award_id, pgm_name, rows=25):\n",
    "    import requests\n",
    "    base_url = \"https://api.crossref.org/works\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"NSF-DOI-Fetcher (mailto:your_email@example.com)\"\n",
    "    }\n",
    "\n",
    "    def filter_award_matches(items):\n",
    "        return [\n",
    "            item for item in items\n",
    "            if any(award_id == a.get(\"award.number\", \"\") for a in item.get(\"award\", []))\n",
    "        ]\n",
    "\n",
    "    try:\n",
    "      \n",
    "        params = {\"filter\": f\"award.number:{award_id}\", \"rows\": rows}\n",
    "        r1 = requests.get(base_url, params=params, headers=headers, timeout=8)\n",
    "        r1.raise_for_status()\n",
    "        filtered_items = filter_award_matches(r1.json()[\"message\"][\"items\"])\n",
    "\n",
    "        if filtered_items:\n",
    "            matched_items = filtered_items\n",
    "        else:\n",
    "\n",
    "            query = f\"NSF {award_id}\"\n",
    "            params = {\"query\": query, \"rows\": rows}\n",
    "            r2 = requests.get(base_url, params=params, headers=headers, timeout=8)\n",
    "            r2.raise_for_status()\n",
    "            raw_items = r2.json()[\"message\"][\"items\"]\n",
    "\n",
    "          \n",
    "            matched_items = []\n",
    "            for item in raw_items:\n",
    "                item_text = str(item).lower()\n",
    "                if award_id in item_text:\n",
    "                    matched_items.append(item)\n",
    "                    \n",
    "        if not matched_items:\n",
    "            return []\n",
    "\n",
    "        results = []\n",
    "        for item in matched_items:\n",
    "            doi = item.get(\"DOI\", \"\")\n",
    "            title = item.get(\"title\", [\"\"])[0]\n",
    "            publisher = item.get(\"publisher\", \"\")\n",
    "            url = f\"https://doi.org/{doi}\" if doi else \"\"\n",
    "            results.append({\n",
    "                \"award_id\": award_id,\n",
    "                \"pgm_ele_0_pgm_ele_name\": pgm_name,\n",
    "                \"title\": title,\n",
    "                \"doi\": doi,\n",
    "                \"url\": url,\n",
    "                \"publisher\": publisher\n",
    "            })\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        return []\n",
    "def fetch_all_papers_parallel(csv_path, max_workers=3):\n",
    "    df_awards = pd.read_csv(csv_path, usecols=[\"awd_id\", \"pgm_ele_0_pgm_ele_name\"])\n",
    "    all_results = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {\n",
    "            executor.submit(\n",
    "                search_crossref,\n",
    "                str(row[\"awd_id\"]),\n",
    "                row.get(\"pgm_ele_0_pgm_ele_name\", \"\")\n",
    "            ): row[\"awd_id\"]\n",
    "            for _, row in df_awards.iterrows()\n",
    "        }\n",
    "\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"üîç Fetching papers\"):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                all_results.extend(result)\n",
    "            except Exception:\n",
    "                continue\n",
    "    df_results = pd.DataFrame(all_results)\n",
    "    before = len(df_results)\n",
    "    df_results = df_results.drop_duplicates(subset=[\"doi\"])\n",
    "    after = len(df_results)\n",
    "    print(f\"‚úÖ Removed {before - after} duplicate DOIs\")\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "017e9667-5cf5-446d-98d2-0ca4ab9b5545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(df,origin):\n",
    "\n",
    "    df_awards = pd.read_csv(origin)\n",
    "  \n",
    "    original_award_ids = set(df_awards['awd_id'].astype(str))\n",
    "    matched_award_ids = set(df['award_id'].astype(str))\n",
    "    unmatched_award_ids = original_award_ids - matched_award_ids\n",
    "    results = len(matched_award_ids )/ len(original_award_ids)\n",
    "\n",
    " \n",
    "    print(f\"Total awards in original file: {len(original_award_ids)}\")\n",
    "    print(f\"Total awards matched in results: {len(matched_award_ids)}\")\n",
    "    print(f\"Awards with no matched papers: {len(unmatched_award_ids)}\")\n",
    "    print(f\"rate of found is {results}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16206af6-7510-430a-8833-04cebf7cd54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "   \n",
    "    file_name = #change names here \n",
    "     \n",
    "    df = fetch_all_papers_parallel(file_name)\n",
    "    df.to_csv()\n",
    "        \n",
    "    print(f\"‚úÖ Done in {time.time() - start:.2f} seconds. Total papers: {len(df)}\")\n",
    "    if df.empty:\n",
    "        print(f\"No DOIs found in {file_name}.\")\n",
    "    else:\n",
    "        df.to_csv()\n",
    "        accuracy(df, file_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
